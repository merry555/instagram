{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from urllib.error import HTTPError\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "import numpy as np\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pymysql\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(driver, timeout):\n",
    "    scroll_pause_time = timeout\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    link_list = []\n",
    "    \n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(scroll_pause_time)\n",
    "                    \n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height != last_height:\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            driver.findElement(By.xpath(\"//a[@href='/p/B67fmKDh5c5/']\")).click();\n",
    "\n",
    "        else:\n",
    "            # If heights are the same it will exit the function\n",
    "            break           \n",
    "            \n",
    "        last_height = new_height        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tag):\n",
    "    options = Options()\n",
    "    # chrome을 전체화면으로 넓히는 옵션입니다.\n",
    "    options.add_argument('--start-fullscreen')\n",
    "\n",
    "    #display = Display(visible=0, size=(1024,768))\n",
    "    #sdisplay.start()\n",
    "    username = \"suuu_0829\"\n",
    "    password = \"rla132489\"\n",
    "\n",
    "    driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "    getdriver = (\"https://www.instagram.com/accounts/login/\")\n",
    "    driver.get(getdriver)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    id_input = driver.find_elements_by_css_selector('#react-root > section > main > div > article > div > div > div > form > div > div > label > input')[0]\n",
    "    id_input.send_keys(username)\n",
    "    password_input = driver.find_elements_by_css_selector('#react-root > section > main > div > article > div > div > div > form > div > div > label > input')[1]\n",
    "    password_input.send_keys(password)\n",
    "\n",
    "    password_input.submit()\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    chrome_options = Options()\n",
    "\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-setuid-sandbox\")\n",
    "\n",
    "\n",
    "    driver.get('https://www.instagram.com/explore/tags/'+tag+'/')\n",
    "\n",
    "    time.sleep(3)\n",
    "    \n",
    "    links = scroll(driver,2)\n",
    "    links = list(set(scroll(driver,2)))\n",
    "    \n",
    "    print(len(links))\n",
    "    \n",
    "    t = random.randrange(0,3)\n",
    "    \n",
    "    collect_driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "    \n",
    "    post_num = 0\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(links)):\n",
    "        file_data = {}\n",
    "        try:\n",
    "            collect_driver.implicitly_wait(3)\n",
    "            #페이지 열기\n",
    "            collect_driver.get('https://www.instagram.com' + (links[i]))\n",
    "            #페이지 소스 가져오기\n",
    "            collect_soup = BeautifulSoup(collect_driver.page_source,'html.parser')\n",
    "            #게시글 작성자 이름\n",
    "            user_id = collect_driver.find_element_by_class_name('_6lAjh').text\n",
    "            file_data['id'] = user_id\n",
    "\n",
    "            #좋아요 개수\n",
    "            like = collect_driver.find_element_by_class_name('Nm9Fw').text\n",
    "            like_count = like.split(' ')[1]\n",
    "            file_data['like'] = like_count\n",
    "\n",
    "            #게시글 생성날짜\n",
    "            post_date = collect_soup.find('time',{'class':'_1o9PC Nzb55'}).get('datetime')  \n",
    "            file_data['date'] = post_date[0:10]\n",
    "\n",
    "            #해시태그\n",
    "            tag_source = collect_soup.find_all('meta',{'property':'instapp:hashtags'})\n",
    "            tag_list = []\n",
    "            for j in range(len(tag_source)):\n",
    "                tag_list.append(tag_source[j].get('content'))\n",
    "            tag_string = \"|\".join(tag_list)\n",
    "            file_data['hashtags'] = tag_string\n",
    "\n",
    "            #댓글\n",
    "            comment_list = []\n",
    "            comment_source = collect_soup.find_all('div',{'class':'C4VMK'})\n",
    "            for k in range(1,len(comment_source)):\n",
    "                comment = comment_source[k].find('span').text\n",
    "                #comment = comment.replace(\"'\",\";\")\n",
    "                c_id = comment_source[k].find('a').text\n",
    "                comment_list.append([comment,c_id])\n",
    "            file_data['comments'] = comment_list\n",
    "\n",
    "            #텍스트 본문\n",
    "            try:\n",
    "                text_source = collect_soup.find('div',{'class':'C4VMK'}).find('span').text\n",
    "            except:\n",
    "                text_source = \"\"\n",
    "            finally:\n",
    "                if str(text_source) == \"인증됨\":\n",
    "                    text_source = collect_soup.find('div',{'class':'C4VMK'}).find_all('span')[1].text            \n",
    "\n",
    "            file_data['text'] = text_source\n",
    "\n",
    "            data.append(file_data)\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(post_num,\"번째 페이지 삭제됨\")\n",
    "            continue\n",
    "\n",
    "        if(post_date[0:10] == '2019-04-07'):\n",
    "            collect_driver.close()\n",
    "            return data\n",
    "        post_num +=1\n",
    "        time.sleep(t)\n",
    "                               \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(data):    \n",
    "    user_id = []\n",
    "    like = []\n",
    "    date = []\n",
    "    hashtags = []\n",
    "    comments = []\n",
    "    post = []\n",
    "\n",
    "    # id, like, date, hashtags, comments, text\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        user_id.append(str(data[i]['id']))\n",
    "        like.append(str(data[i]['like']))\n",
    "        date.append(str(data[i]['date']))\n",
    "        hashtags.append(str(data[i]['hashtags']))\n",
    "        comments.append(str(data[i]['comments']))\n",
    "        post.append(str(data[i]['text']))\n",
    "\n",
    "    result = pd.DataFrame({'id':user_id, 'like':like, 'date':date, 'hashtags':hashtags, 'comments':comments, 'post':post})\n",
    "\n",
    "    result.to_csv(\"instagram.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(tag):\n",
    "    data = get_data(tag)\n",
    "    print(len(data))\n",
    "    print(\"=======================\")\n",
    "    make_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    tag = 'parasitemovie'\n",
    "    main(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
